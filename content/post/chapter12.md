---
title: "Chapter12"
date: 2019-06-22T19:23:11+08:00
draft: true
tags: ["data structure","treap","skip list"]
---

# Finger Search Tree

Finger Search指从finger $x$出发寻找$y$。比如有序数组，从$x$开始倍增，这里不能acm里的那种倍减trick，因为那样是$O(\log n)$的，而倍增是$O(\log d)$的。$d$是$x$和$y$在有序数组中的排名差。如下图所示，意识流一下就是那样了。

![fig12-1](/pic/data structure/12-1.jpg)

## Dynamic Finger Search Trees

上面的倍增已经解决了这个问题，但是有序数组不能高效插入删除，所以需要Dynamic Finger Search Tree。

## Level Linked (2,4)-Trees

B树它leile，2-4个孩子的B树，基于finger的插入删除均摊复杂度为$O(1)$，~~期望倒是会，均摊不会分析~~。它与B树的不同在于所有的边都是双向的，并且同层相邻节点之间边相连。

![fig12-2](/pic/data structure/12-2.jpg)

不妨令$x<y$，走到父亲$v$，同时判断$v$的右邻居$v'$是否是$y$的父亲。当停止时：

若因为停在共同的祖先$c$，则$c$至少有一个子树隔开$x,y$，这颗子树里的点都在$x,y$之间，它的点数就bound住了高度。

若是因为$v$的右邻居$u'$是$y$的父亲，此时$x$在$v$的右子树，$y$在$v$的父亲的右邻居$u'$的左子树，只需要考虑$v$和$u'$的子树的末端相邻点，则变成第一种情况。Q.E.D.

综上，用(2,4)-Tree的时间复杂度是$O(\log d)$的。



## Randomized Finger Search Trees

弱智书乱排版，建议先看14章。

这节写的比较玄，背景知识参考[这里](/data structure/treaps.pdf)。

### treap

treap的思路就是一个二叉搜索树，但是它不像平衡树那样根据树高左旋右旋，而是根据随机产生的第二优先值维护一个堆（下面只考虑小根堆）。比如当前子树根为A，左子树根为B，右子树为C，不妨B的第二优先值最小，则B右旋成根，它的右子树变成A的左子树。~~单旋谁不会啊~~

下图字母是键值，数字是第二优先值。

![fig12-3](/pic/data structure/12-3.jpg)

**插入**：首先按二叉搜索树将其真实值插入到叶子，然后就堆插入元素那样按第二优先值从最底层往上调，调整就是用的左旋右旋。

**删除**：先找到这个节点，然后将其旋转到叶子，最后删除掉，逆着插入的操作

**分裂**：即分裂成比某个值$\pi$大的和小的两个treap。插入$\pi$，令它的第二优先值为无穷小，那么插入完它为根，且由二叉搜索树得，它的两个子树是要求的treap。

**合并**：用$\pi$作为根合并两棵treap，然后将根用删除的操作删除。

以上4个操作的复杂度均由treap的高度决定，可证明随机情况下高度为$O(\log n)$。

**引理**：将元素按键值递增为数组A，在treap中第i小的元素为第k小元素的祖先等价于i的第二优先值是A[i..k]中最小的(i<k)。在treap中第i小的元素为第j小元素的祖先等价于i的第二优先值是A[j..i]中最小的(j<i)

**证**：

⇒：考虑当前treap的根是谁。若是i，则得证；若是k，则矛盾；若在区间(i,k)，则i和k不在同一子树，矛盾；若不在区间[i,k]，则是更小的treap，递归得证。

⇐：依然分类讨论根。Q.E.D.

这个引理在下面的证明中会被直接使用，就不明说了。

**定理1**：以上四个操作期望复杂度都是$O(\log n)$的。

**证**：考虑每个元素深度的期望，即祖先个数的期望，即每个点是其祖先的概率，等价于每个区间中它是最小的，将区间拆成以它结尾的和以它开头的分开计算，两个都是$\sum\frac{1}{i}=O(\log n)$级别。所以以上操作都是$O(\log n)$的。

**定理2**：证明树高$O(\log d)$是W.H.P.的。

**证**：W.H.P.通常很多是用chernoff bound来证明的，类似树高的期望证明，将区间拆成两个，每个补充到n个随机变量，每个直接用chernoff bound即可。Q.E.D.

接下来分析基本来自96年Raimund Seidel的那篇Randomized Search Trees。~~或者算法导论红黑树那章最后一道作业题。~~

**定理3**：给定finger下，插入删除复杂度为$O(1)$。

**证**：定义点v的left spine为从v开始只走左边的最长路径，right spine为从v开始只走右边的最长路径。

对于待删除的点x，定义$SL(x)$为x的左孩子的right spine，$SR(x)$为x的右孩子的left spine。虽然很别扭，但是这个定义很符合单旋的性质：若x左旋，即x变成左孩子，x的右孩子的左子树变为x的右子树，则$SL(x)$不变，$SR(x)-1$。若右旋，即x变为右孩子，x的左孩子的右子树变为x的左子树，则$SL(x)-1$，$SR(x)$不变，所以每次旋转$SL(x)+SR(L)$减少一。~~左、右两个字我已经不认识了~~。

注意到$SL(x)$显然是$x$到$x-1$的路径（这里所有的$x$都是指A数组中第$x$个元素），若$x-1$不在$x$的子树中，则$x$没有左孩子了，否则$x-1$一定在right spine的终点。所以期望意义下$SL(x)$为A[1...x-1]中所有$x-1$的祖先减去$x$的祖先，即$SL(x)=\sum_{i=1}^{x-1}\frac{1}{(x-i+1)(x-i)}=1-\frac{1}{x}$。同理$SR(x)=1-\frac{1}{n+1-x}$。

也就是说给定finger的情况下，$O(1)$时间可以删除它，由于插入为删除的逆过程，给定finger时也是$O(1)$时间插入。Q.E.D.

**定理4**：接下来证明$x$到$y$的路径长度期望是$O(\log d)$。

**证**：考虑$LCA(x,y)=v$，则路径长度的期望是$x$到$v$的路径中点数的期望+$y$到$v$的路径中点数的期望，类似上面的思路求和即可，自己算去。Q.E.D.

个人觉得定理2的证明可以套过来证明定理3和4W.H.P.，作者为什么不证啊？

背景知识介绍完了，可以开始介绍书上的内容了。书上讲了$O(\log d)$期望时间finger search的算法，定理4无法被使用的主要原因是$LCA$无法求，因为$y$的位置并不知道。算法是$x$不断的沿着treap往上走，当走到$v$，若$x<v\le y$，则$v$可能是$LCA$，但是只有当$x<y<v$时才能保证LCA已经找到，这个期望不太好算，。为了解决这个问题，论文里的方法时添加额外信息，比如每个点添加它的子树中最大和最小的元素是多少，这样旋转容易维护，但是插入删除沿着树往上更新，显然也是沿着spine更新，所以期望是$O(1)$。书上的方法很妙，以$v$为潜在的根往下探，注意这里$x$上探一步同时$v$下探一步，当上探$O(\log d)$找到真正的$LCA$时，再下探$O(\log d)$次就能找到。

### Skip Lists

skip list的思路是当前一层的节点以$\frac{1}{2}$的概率成为上一层的节点，并将这两个节点连接起来，同层的节点也要连接起来。所以每个节点是一个变长的数组，记录每层的内容。

**查找**：从顶层开始，尽可能的往右走，保证当前节点的值不大于目标节点，走到不能走则前往下一层的同列节点。

**插入**：按照查找的过程查找位置，不同在于需要记录每层最后一个不大于目标节点的节点。然后随机生成这个节点的层数，将其连在查找在记录下的节点后。

**删除**：类似查找并记录，接着在每层中删除即可。

直接计算每一数的高度大于l的概率，然后直接算期望得高度为$O(\log n)$，随便union bound一下即可证明W.H.P.高度为$O(\log n)$。所以以上操作的时间复杂度为$O(\log n)$W.H.P.。