<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>approximation algorithm on syx的日志</title>
    <link>cartershi.github.io/blog/tags/approximation-algorithm/</link>
    <description>Recent content in approximation algorithm on syx的日志</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 24 Jul 2019 14:53:16 +0800</lastBuildDate>
    
	<atom:link href="cartershi.github.io/blog/tags/approximation-algorithm/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>HAAM_chapter7</title>
      <link>cartershi.github.io/blog/post/haam_chapter59/</link>
      <pubDate>Wed, 24 Jul 2019 14:53:16 +0800</pubDate>
      
      <guid>cartershi.github.io/blog/post/haam_chapter59/</guid>
      <description>本文的目标是找一棵联通树，使得$\sum_{u,v\in V}\lambda(u,v)d_T(u,v)$最小，下面称为cost，树T的cost写为c(T)。
Minimum Routing Cost Spanning Tree 这里设置为$\lambda(u,v)=1$，所以目标变成了是找一棵联通树，cost为任两点之间的距离和。
Shortest-Paths Trees and Solution Decomposition 做法一：取图的median r，从r开始找最短路径树。对于任意的树Y的cost小于等于2n倍所有点到根的距离和（三角不等式），这恰好median决定的东西。累加起来是图上面的两点间距离和，优于最优树上的cost。这样得到一个2近似。
做法二：基于decomposition，考虑最优树T上的centroid为根r，T的cost至少是n倍所有点到r的距离和，又由于任意树的cost小于等于2n倍所有点到根的距离和，所以以r为根的最短路径树是T的2近似。只要穷举所有的根找最小即可。
Routing Loads, Separators, and General Stars 接下来是一堆定义，又是利用树上的性质。$l(T,e)=2x(n-x)\le2\frac{n}{2}\cdot\frac{n}{2}$，其中x是$T-e$中较小的连通分支的大小。实际上l表示两个连通分支中的点的最短路经过e的次数，所以可以得到$c(T)=\sum_{e\in T} l(T,e)w(e)$。注意所有$l$对树进行一次bfs即可得到，于是$c(T)$线性时间可以计算。
minimal δ-separator是以centroid为根的树中子树点数多余$\delta n$个的所有点形成的联通树。
Definition 59.1 Let R be a tree contained in graph G. A spanning tree T is a general star with core R if each vertex is connected to R by a shortest path.
上面的定义不需要R是最短路径树。
Lemma 59.3 If T is a general star with core S, $c(T)\le 2n\sum{v\in V}d{G}(v,S)+\frac{n^2}{2}w(S)$</description>
    </item>
    
    <item>
      <title>HAAM_chapter7</title>
      <link>cartershi.github.io/blog/post/haam_chapter7/</link>
      <pubDate>Fri, 19 Jul 2019 21:09:38 +0800</pubDate>
      
      <guid>cartershi.github.io/blog/post/haam_chapter7/</guid>
      <description>LP Rounding and Extensions Nondeterministic Rounding Independent Rounding 集合覆盖，用LP的解作为集合被选取的概率，挑选$c\log n$次。这样期望大小有界，并且WHP覆盖所有的元素。
条件满足问题，每个元素$\frac{1}{2}$的概率为正，得到一个结果，另外以LP的解作为元素被选的概率挑选，取两者大的。
Dependent Rounding simultaneously rounding ：最小割问题（限制为某些点必须被割开），随机选取一个$u\in[\frac{1}{2},1]$，把比u大点与s放在一起。
Rounding against a Hyperplane：最大割问题，高级算法讲过。
Extensions：distributions on level sets、 the pipage rounding method、the level set based method、digital halftoning、cardinality constraints。鸽了
Deterministic Rounding Scaling：点覆盖选取所有至少$\frac{1}{2}$的点。
Filter and Round：Approximation Algorithms for Geometric Median Problems中介绍。
Iterated Rounding：上一章有。
Pipage Rounding：将小数解round成整数解，过程中保证目标函数不会增加太多。具体做法是设计一个新的目标函数，它是凸函数且与原函数近似。
Decompose and Round：几何问题可用。</description>
    </item>
    
    <item>
      <title>HAAM_chapter6</title>
      <link>cartershi.github.io/blog/post/haam_chapter6/</link>
      <pubDate>Mon, 15 Jul 2019 20:11:12 +0800</pubDate>
      
      <guid>cartershi.github.io/blog/post/haam_chapter6/</guid>
      <description>Linear Programming 线性规划有两个常用的方法：rounding和dual，ruonding一般需要将整数规划用线性规划解，然后根据具体情况将分数解转化成整数解。dual是同时优化原问题和对偶问题，不要调用线性规划求解器。本章主要是rounding。
6.2 Rounding 需要明确的是basic feasible solution的定义，满足真正独立的有用限制的解。其实就是让变量尽可能多为0的合法解，也是simplex跑出来的结果。
makespan：将每个部分分配的工作匹配到一个具体的机器上即可。匹配工作到机器这件事能成立需要考虑的basic feasible solution的性质，规划中的限制最多n+m个，也就是说数组A的秩最多为n+m，所以解最多n+m个元素非0。若有k个工作被部分分配，最少在结果中占2k个位置，剩下n-k个工作占1个位置，即最少有n+k个元素非0，所有最多m个工作被部分分配。这些部分分配的工作形成pseudoforest（原因看不懂了，坑）。直接用LP比IP小且匹配得到2近似。 METRIC FACILITY LOCATION：这里考虑最简单的直接在client上建facility的情况。思路是对于所有点按它们的平均距离递增排序，然后尽可能的选4/3倍平均距离的不相交的球体。每个球体选择一个最便宜的地点开设facility，每个client选一个最近facility供应。证明第一块好像又跳了很大一部坑，第二部分容易理解，不过觉得8/3写成4/3了。
GENERALIZED STEINER NETWORK：将relax后的式子迭代的计算选取$\ge\frac{1}{2}$的边。这里有个非常复杂的证明。
6.3 Randomized Rounding MAXIMUM COVERAGE：将LP解得的x看成选取这个集合的概率，然后以这样的概率随机取k个。对每个元素，可以得到它被覆盖的概率的下界（注意下界证明的不等式不是恒成立，而是题中范围恒成立），从而得到被覆盖的期望的下界。
CONGESTION MINIMIZATION：每条路径被选择的概率等于它LP的结果。得到每条边被覆盖次数的期望。还可用chernoff bound得到每条边覆盖次数的概率结果（书上又跳了一步union bound）。
6.4 Metric Spaces MINIMUM MULTICUT：这个问题就是把k对点给割开，求最小割。$O(\log k)$的近似算法是对于每个边给一个权重，任一对点之间的任意条路劲都需要权重和$\ge1$，对这个线性规划给出一个解之后，用每条边上的权作为边权建立新图，这是k对点之间的最短路都至少为1。接着对于这2k个点中的每一个点w和一个实数$\rho$，定义$E{\rho}$为所有的边$e=uv$，使得$d(u,w)\le\rho,d(v,w)&amp;gt;\rho$。构造定义$f&amp;rsquo;(\rho),f(\rho)$，保证$\exists\rho\in[0,\frac{1}{3}],f&amp;rsquo;(\rho)\le 3f(\rho)\ln k$。算法就是每个未删除的点对，选一个点，找到它对应的上述$\rho$，将所有与它距离不超过$\rho$的点一起删除，并且这样导致的割边记入cut中，这里的割边其实就是定义中的$E{\rho}$，这样其实是删除了分支（不一定联通），由于$\rho\le\frac{1}{3}$，所以一个点对不可能被同时删除，当它们某次被分开时，一定被割开了，所以这是一个割。由于每条边最多被1次，所以对这k次割的f值求和可得不会超过规划目标得两倍，然后用f‘和f的不等式得近似比。
SPARSEST CUT：鸽了
MINIMUM LINEAR ARRANGEMENT：V个点赋予1..V的排列$\varphi$，最小化$\sum_{{u,v}\in E}|\varphi(u)-\varphi(v)|$。关键的发现是所谓的well spread，这个relax到一个距离度量，可以写成一个线性规划。接下来用rounding来把metric变成排列，有点像MINIMUM MULTICUT的分析，但是鸽了。</description>
    </item>
    
    <item>
      <title>HAAM_chapter4</title>
      <link>cartershi.github.io/blog/post/haam_chapter4/</link>
      <pubDate>Thu, 11 Jul 2019 11:37:54 +0800</pubDate>
      
      <guid>cartershi.github.io/blog/post/haam_chapter4/</guid>
      <description>Greedy Methods
贪心方法大全
Set Cover：常用分析，charge scheme。
Shortest Superstring Problem：包含所有字符串的超串，这个问题可以常数近似。
Steiner Trees：边权版不提了，点权版每次贪心的挑选一个spider，直至全覆盖。
K-Centers：找k个中心，使得每个点到中心的最短距离都小。每次挑选一个距离当前中心最远的点加入中心。证明思路就是OPT的k个点的最优半径必然覆盖所有点，而贪心中第K+1次挑选的距离就是贪心的答案，这K+1个点必然有两个比OPT中某个点覆盖，这两点的距离两次放缩得不小于贪心的答案，再由三角不等式。
Connected Dominating Sets：
Scheduling：对于一种特殊的情况：一台机器且所有工作价值相同，一个贪心方法是挑选最早完成的工作。
Minimum-Degree Spanning Trees：在度数不超过d的情况下的最小生成树，这个问题在度的限制不放宽的情况下不可近似，但在度$O(\log n)$近似下可以得到$O(\log n)$的树。算法是不断用匹配选择度不超过d的森林拼接成树。
Maximum-Weight b-Matchings：最大权匹配，但每个点可被用b次。多项式可解但是可极快近似，对边排序，然后不断的加边。
Primal-Dual Methods：点覆盖著名应用。
Greedy Algorithms via the Probabilistic Method：组合数学利器，maxcut著名应用，独立集比较著名，接下来gele</description>
    </item>
    
    <item>
      <title>HAAM_chapter5</title>
      <link>cartershi.github.io/blog/post/haam_chapter5/</link>
      <pubDate>Sun, 07 Jul 2019 12:13:42 +0800</pubDate>
      
      <guid>cartershi.github.io/blog/post/haam_chapter5/</guid>
      <description>5.2 对于集合覆盖那个著名的贪心，如果每次并不选择密度最小的集合$Si$，而是对于剩下x个未选择的元素，一个oracle可以给出最小密度$\alpha(x)$近似的，那么$\frac{\sum w(Si)}{w(C*)}\le\int{n-|\cup{S&amp;rsquo;\in C_i}S&amp;rsquo;|}^n{\frac{\alpha(x)}{x}dx}$，这个结论的证明不是很难，需要理解的地方在于递归证明里第一个不等式是需要进行两次放缩的。而(5.2)的递归公式也是隐藏了一个放缩在里面。
这个结论有意思的地方是只要挑选不超过$1-\frac{1}{e}$倍的元素，贪心得到的集合权重不会超过$w(C*)$。
5.3 注意这里DST的定义里输入是给定根r的，DST显然是k-DST的一种情况，k-DST规约到n-shallow k-DST，每层都是原图的点，两层之间的边是原图的边，加自己到自己的零边。
对于k-DST问题，整体的思路是：k-DST等价于原图G的传递闭包TC(G)的k-DST；接着在TC(G)上找l-shallow k-DST，由lemma5.2，它的最优解是k-DST的近似；由lemma5.1，TC(G)上的l-shallow k-DST等价于l层有向无环图上的k-DST；5.4节给出了有向无环图上的k-DST的近似算法。最终用两个等价问题的两个近似解决了一般图上k-DST问题。光这样还没完，这个算法最牛叉的地方在于它的近似比直接依赖于有向无环图上的k-DST的近似算法的过程，即那个类似集合覆盖的过程直接这么复杂的过程书上为什么不讲清楚呢
5.4 这里最难理解的地方是aug树的权重计算了在之前可能已经被加入树中的边，其实这无所谓，我们得到的树的权重不计算重边，所以不会大于aug树的权重和。5.2节的结论说的就是集合权重的和，即得到的树的权重与最优树的权重依然满足这样的结论。（直接思考5.2的证明过程即可）。
算法其实很简单，但是claim5.2的证明非常妙：最优树的参数k&amp;rsquo;也必然k&amp;rsquo;-DST调用，那次调用中累计aug树的过程其中有一个树满足那个条件，记它包含k&amp;rdquo;的目标，则k&amp;rdquo;-DST调用时必然产生这棵树作为候选（由贪心决定），所以aug树的密度不会超过它。这个树构造还用了一个技巧：在第一次超越时，即$k&amp;rdquo;\ge\frac{k&amp;rsquo;}{l-1}$，这个超越虽然会使得分析变得麻烦，但是保证了$k&amp;rdquo;&amp;gt;0$且存在。分析的思路是考虑发生超越的之前的每个时刻的情况，总的最优解在当前的密度大于等于当前最优密度，用当前最优密度的递归式进行放缩，再对总的最优解在当前的密度进行放缩即可。
在分层图上，运行时间的分析只需要注意每个点在构造的图上有n个孩子，每个孩子调用k次k-DST。近似比的分析直接用集合覆盖。
对于一般图上k-DST，过程麻烦一点，需要考虑直接在原图上集合覆盖，这样的一棵树包含k*个目标，则它其实是K*-DST的最优解。所以在分层图上有一个近似的最优解，然后用分层图上k-DST的近似算法得到近似最优解的近似解，这就可以直接用5.2节的结论了。实际上就是分层图上k-DST的近似算法的解是原图上的最小剩余密度树的近似，所以可解。
在GST上，只考虑树上的k-GST，依然是不断的求集合覆盖，不同在于树可以容易的改变高度和度数。接着使用geometric search的思路bound调用子树k-GST的次数，可以得到一个与原树高无关的多项式算法。细节参考写的&amp;rdquo;A greedy approximation algorithm for the group Steiner problem“博客。
Appendix 引理的证明思路是对最优的k-DST进行height reduction，即将极小的重节点连到根上，对极大的轻节点进行递归reduction。考虑根开始的第一次reduction，被连到根上的节点最多$\alpha$个，所以树最多被重复$\alpha$倍，重点在于被复制的路径必然是重节点的父亲，所以它不会被再次复制，所以每次只有原来树上的路径被复制，而高度可以用直接bound。</description>
    </item>
    
    <item>
      <title>近似算法手册</title>
      <link>cartershi.github.io/blog/post/%E8%BF%91%E4%BC%BC%E7%AE%97%E6%B3%95%E6%89%8B%E5%86%8C/</link>
      <pubDate>Sun, 07 Jul 2019 12:08:25 +0800</pubDate>
      
      <guid>cartershi.github.io/blog/post/%E8%BF%91%E4%BC%BC%E7%AE%97%E6%B3%95%E6%89%8B%E5%86%8C/</guid>
      <description>再开一个新坑Handbook of Approximation Algorithms and Metaheuristics，简称HAAM，在这里。这本书的证明实在跳跃，难以看懂，还是记下来好。
如有侵权，请联系删除。</description>
    </item>
    
  </channel>
</rss>