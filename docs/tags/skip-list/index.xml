<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>skip list on syx的日志</title>
    <link>cartershi.github.io/tags/skip-list/</link>
    <description>Recent content in skip list on syx的日志</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 24 Jun 2019 12:06:55 +0800</lastBuildDate>
    
	<atom:link href="cartershi.github.io/tags/skip-list/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>chapter14</title>
      <link>cartershi.github.io/post/hdsa_chapter14/</link>
      <pubDate>Mon, 24 Jun 2019 12:06:55 +0800</pubDate>
      
      <guid>cartershi.github.io/post/hdsa_chapter14/</guid>
      <description>Randomized Dictionary Structures 引言 worst-case高效的数据结构太复杂并且写起来很麻烦，所以人们试图优化一串操作的总代价，而非单次操作的代价，这就是所谓的均摊复杂度。从随机的角度，目的是限制操作的期望并是的超出阈值的概率不大。
为了简化分析，本章仅考虑支持插入、删除、搜索操作的字典，字典集为有限整数，并且元素之间两两不相同。
本章讨论的随机算法是Las Vegas algorithm，即只要返回结果，结果就是对的。另外一种是Monte Carlo algorithm，运行时间固定，但是结果不一定对。
$1-O(\beta^{-n}),1-O(n^{-c})$都是high confidence bound，$1-O((\log n)^c)$是very good confidence bound，$1-O(\beta^{-\alpha})$是constant probability bound。对于本章，通常考虑运行时间与期望时间的bound。
然后是一堆概率论的基础知识。
Skip Lists skip list的思路是当将有序链表$S_0$中随机一些节点复制进入$S_1$，接着从$S_1$复制一些节点到$S_2$，直至顶层为空。即前一层的节点以某个概率$p$继续成为上一层的节点，并将这两个节点连接起来，同层的节点也要连接起来。所以每个节点是一个变长的数组，记录每层的内容。如下图所示，32是一个节点，它有6层，每层之间相互连接，这样方便往右下搜索。
直接计算每一数的高度大于l的概率，然后直接算期望得高度为$O(\log n)$，随便union bound一下即可证明W.H.P.
空间复杂度期望$O(n)$，W.H.P.就Chernoff bound一下n个随机变量层高得空间复杂度$O(n)$。
查找：从顶层开始，尽可能的往右走，保证当前节点的值不大于目标节点，走到不能走则前往下一层的同列节点。
插入：按照查找的过程查找位置，不同在于需要记录每层最后一个不大于目标节点的节点。然后随机生成这个节点的层数，将其连在查找在记录下的节点后。
删除：类似查找并尝试在每层中删除即可。注意可能产生的空行。
以上三个操作运行时间都是由查找时间决定的。我们逆向考虑查找的过程，从底层0到顶层r的过程中每次进入上层时这个值都是上层中最接近x的值，即每次都是以$p$的概率往上走，以$1-p$的概率往左走，这等价于r个几何随机变量$Y_i$，每个表示第$i$层往左走的步数。注意到第$r$层为空，所以总的搜索步数为$Y=r+\sum_{i=0}^{r-1}Y_i$。这个转化也太帅了！
令$H_r=\sum_{i=0}^{r-1}Y_i$，由$P[r &amp;gt; 4\log n]&amp;lt;\frac{1}{n^3}$，$P[H_r&amp;gt;16\log n]&amp;lt;\frac{1}{n^2}\ for\ n\ge 32$是先全概率公式展开，再用Chernoff bound，则$P[H_r&amp;gt;16\log n\cup r &amp;gt; 4\log n]&amp;lt;\frac{1}{n^2}+\frac{1}{n^3}=O(\frac{1}{n^2})$，即$P[Y=O(\log n)]&amp;gt;1-O(\frac{1}{n^2})$。对于每一个x，$P[Y\in O(\log n)]&amp;gt;1-O(\frac{1}{n^2})$，所以n+1种的路径均为$O(\log n)$的概率至少为$1-O(\frac{1}{n})$，这就证明了三个操作W.H.P都是$O(\log n)$。
Randomized Binary Search Trees Randomly Built Binary Tree(RBBT)指只有随机插入，即给定序列的树，插入在不同间隙里的概率是相等的。这个假定完全不符合实际，并且删除操作会使得RBBT退化严重，高度达到$\sqrt n$。
RBST和treap不同，它不随机产生第二有限值，而是保存当前节点的子树点数，并维护这样的性质$P[size(L)=i|size(T)=n]=\frac{1}{n}$，即不同大小左子树的概率相等，相当于有序列表里每个元素等概率为根。
以下建议全看原论文，好神难啊QAQ
插入：当插入一个n个点树时，随机一个0..n的数，若不是n，进入相对于的子树继续插入，否则x应当为根，递归的产生$T&amp;lt;,T&amp;gt;$，不妨设x小于根，根r及其右孩子因设为$T&amp;gt;$，递归调用$r.L,x,T&amp;lt;,T&amp;gt;.L$，这是指$T&amp;lt;$需要继续添加，$T&amp;gt;$已经填好了根和右子树，只需要填左子树。
删除：先正常的搜索到这个节点，然后将这个节点的左子树和右子树join起来，join是判断随机产生的数[1,size(T)-1]是在左子树还是右子树，若在左子树，则将左孩子的右子树与右子树join，否则将右孩子的左子树与左子树join。
插入的复杂度与普通插入一样，用递归证明产生的两个子树也是RBST，同时$T&amp;gt;.R$也是RBST，则证明$T&amp;gt;$是RBST只需要证明根也满足条件，注意这个根是原树的根，所以用条件概率即可的证明。
现在考虑插入的结果，若未插入在根，则第一次会使概率变为$\frac{1}{n+1}$，递归得到一个RBST，原树剩下的部分也是RBST。否则用上面的结论另外注意x也是$\frac{1}{n+1}$的概率。
对于join，递归证明join后的子树是RBST，左孩子的左子树是RBST，右子树更小的join结果，也是RBST，互相独立，每个元素为根的概率是$\frac{1}{n+m}$。</description>
    </item>
    
    <item>
      <title>Chapter12</title>
      <link>cartershi.github.io/post/hdsa_chapter12/</link>
      <pubDate>Sat, 22 Jun 2019 19:23:11 +0800</pubDate>
      
      <guid>cartershi.github.io/post/hdsa_chapter12/</guid>
      <description>Finger Search Tree Finger Search指从finger $x$出发寻找$y$。比如有序数组，从$x$开始倍增，这里不能acm里的那种倍减trick，因为那样是$O(\log n)$的，而倍增是$O(\log d)$的。$d$是$x$和$y$在有序数组中的排名差。如下图所示，意识流一下就是那样了。
Dynamic Finger Search Trees 上面的倍增已经解决了这个问题，但是有序数组不能高效插入删除，所以需要Dynamic Finger Search Tree。
Level Linked (2,4)-Trees B树它leile，2-4个孩子的B树，基于finger的插入删除均摊复杂度为$O(1)$，期望倒是会，均摊不会分析。它与B树的不同在于所有的边都是双向的，并且同层相邻节点之间边相连。
不妨令$x&amp;lt;y$，走到父亲$v$，同时判断$v$的右邻居$v&amp;rsquo;$是否是$y$的父亲。当停止时：
若因为停在共同的祖先$c$，则$c$至少有一个子树隔开$x,y$，这颗子树里的点都在$x,y$之间，它的点数就bound住了高度。
若是因为$v$的右邻居$u&amp;rsquo;$是$y$的父亲，此时$x$在$v$的右子树，$y$在$v$的父亲的右邻居$u&amp;rsquo;$的左子树，只需要考虑$v$和$u&amp;rsquo;$的子树的末端相邻点，则变成第一种情况。Q.E.D.
综上，用(2,4)-Tree的时间复杂度是$O(\log d)$的。
Randomized Finger Search Trees treap细节完全不介绍的吗？背景知识参考这里。
treap treap的思路就是一个二叉搜索树，但是它不像平衡树那样根据树高左旋右旋，而是根据随机产生的第二优先值维护一个堆（下面只考虑小根堆）。比如当前子树根为A，左子树根为B，右子树为C，不妨B的第二优先值最小，则B右旋成根，它的右子树变成A的左子树。单旋谁不会啊
下图字母是键值，数字是第二优先值。
插入：首先按二叉搜索树将其真实值插入到叶子，然后就堆插入元素那样按第二优先值从最底层往上调，调整就是用的左旋右旋。
删除：先找到这个节点，然后将其旋转到叶子，最后删除掉，逆着插入的操作
分裂：即分裂成比某个值$\pi$大的和小的两个treap。插入$\pi$，令它的第二优先值为无穷小，那么插入完它为根，且由二叉搜索树得，它的两个子树是要求的treap。
合并：用$\pi$作为根合并两棵treap，然后将根用删除的操作删除。
以上4个操作的复杂度均由treap的高度决定，可证明随机情况下高度为$O(\log n)$。
引理：将元素按键值递增为数组A，在treap中第i小的元素为第k小元素的祖先等价于i的第二优先值是A[i..k]中最小的(i&amp;lt;k)。在treap中第i小的元素为第j小元素的祖先等价于i的第二优先值是A[j..i]中最小的(j&amp;lt;i)
证：
⇒：考虑当前treap的根是谁。若是i，则得证；若是k，则矛盾；若在区间(i,k)，则i和k不在同一子树，矛盾；若不在区间[i,k]，则是更小的treap，递归得证。
⇐：依然分类讨论根。Q.E.D.
这个引理在下面的证明中会被直接使用，就不明说了。
定理1：以上四个操作期望复杂度都是$O(\log n)$的。
证：考虑每个元素深度的期望，即祖先个数的期望，即每个点是其祖先的概率，等价于每个区间中它是最小的，将区间拆成以它结尾的和以它开头的分开计算，两个都是$\sum\frac{1}{i}=O(\log n)$级别。所以以上操作都是$O(\log n)$的。
定理2：证明树高$O(\log d)$是W.H.P.的。
证：W.H.P.通常很多是用chernoff bound来证明的，类似树高的期望证明，将区间拆成两个，每个补充到n个随机变量，每个直接用chernoff bound即可。Q.E.D.
接下来分析基本来自96年Raimund Seidel的那篇Randomized Search Trees。或者算法导论红黑树那章最后一道作业题。
定理3：给定finger下，插入删除复杂度为$O(1)$。
证：定义点v的left spine为从v开始只走左边的最长路径，right spine为从v开始只走右边的最长路径。
对于待删除的点x，定义$SL(x)$为x的左孩子的right spine，$SR(x)$为x的右孩子的left spine。虽然很别扭，但是这个定义很符合单旋的性质：若x左旋，即x变成左孩子，x的右孩子的左子树变为x的右子树，则$SL(x)$不变，$SR(x)-1$。若右旋，即x变为右孩子，x的左孩子的右子树变为x的左子树，则$SL(x)-1$，$SR(x)$不变，所以每次旋转$SL(x)+SR(L)$减少一。左、右两个字我已经不认识了。
注意到$SL(x)$显然是$x$到$x-1$的路径（这里所有的$x$都是指A数组中第$x$个元素），若$x-1$不在$x$的子树中，则$x$没有左孩子了，否则$x-1$一定在right spine的终点。所以期望意义下$SL(x)$为A[1&amp;hellip;x-1]中所有$x-1$的祖先减去$x$的祖先，即$SL(x)=\sum_{i=1}^{x-1}\frac{1}{(x-i+1)(x-i)}=1-\frac{1}{x}$。同理$SR(x)=1-\frac{1}{n+1-x}$。
也就是说给定finger的情况下，$O(1)$时间可以删除它，由于插入为删除的逆过程，给定finger时也是$O(1)$时间插入。Q.E.D.
定理4：接下来证明$x$到$y$的路径长度期望是$O(\log d)$。</description>
    </item>
    
  </channel>
</rss>